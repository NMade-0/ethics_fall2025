---
title: 'ALG Blog 1: Exception to the Rule?!'
date: 2025-09-24
permalink: /posts/2025/09/blog-post-2/
tags:
  - case study
  - ethics
  - data-driven
---

**Words by an optimist – The Exception Problem**

I recommend reading the MIT Case Study here before my rambling:
[The Right to Be an Exception to a Data-Driven Rule](https://mit-serc.pubpub.org/pub/right-to-be-exception/release/2)

Summary
---
The whole point of this case study is that algorithms and data-driven rules *always* make exceptions—people who fall through the cracks. The article argues that people shouldn’t be punished for being the unlucky outlier, and that decision-makers need to justify when it’s fair to apply a data-driven rule to a specific individual.

## Q1: What is a data-driven rule, and what does it mean to be a data-driven exception?  
A data-driven rule is just a fancy way of saying "let the algorithm decide." Think of it like Netflix’s recommendation system deciding what show you should watch or an AI system deciding who gets a loan. A *data-driven exception* is when the rule works for most people but screws you over. Like, you’re actually qualified for the loan, but the dataset didn’t account for someone like you. An exception isn’t always an "error"—the algorithm might be doing exactly what it was trained to do, but it still doesn’t fit your reality.

## Q2: What makes data-driven decisions different from human ones?  
Humans are inconsistent, but that’s sometimes good. One employer might reject you, another might see potential. Algorithms, though? Once they lock onto a pattern, they can shut you out systemically. If *every* employer uses the same AI filter, being an exception means you’re stuck in the same loop forever. At least humans make different mistakes.

## Q3: Benefits and downsides of individualization  
Benefit: more personal treatment. If a loan algorithm knows about your actual job history, not just your zip code, that’s more fair.  
Downside: privacy nightmare. Do we really want decision-makers scraping through every corner of our lives to “individualize” us? Also, adding more data doesn’t always fix the problem—sometimes it just overfits the system.

## Q4: Why is uncertainty so critical?  
Because no matter how much data you throw in, randomness still exists. The case study called this *aleatoric uncertainty*—basically, stuff you just can’t predict. When the stakes are high (like criminal sentencing), accuracy alone isn’t enough. You can’t just say "the model is 95% accurate" and send someone to jail. Without factoring in uncertainty, you risk making irreversible mistakes on the unlucky 5%.

## My Question  
If we give people "the right to be an exception," how do we prevent everyone from claiming it at once? Wouldn’t that water it down? I’m curious how we balance protecting real exceptions without letting the idea become meaningless.

## Reflection  
I liked this case study because it felt practical. As a computer scientist, I can easily see myself coding something that accidentally leaves people behind. It makes me think twice about saying "eh, 95% accuracy is good enough." Someone *is* the 5%. And the point is, if that person’s life is on the line, they deserve better than just being “statistical noise.”  

Final thought by the optimist: Exceptions are rare, but so are diamonds. Just because someone doesn’t fit the rule doesn’t mean they don’t deserve to shine.
