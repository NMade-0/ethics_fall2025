---
permalink: /casestudy/
title: "The Future of Employment"
author_profile: true
layout: default
---

# Case Study: The Future of Job sustainability with AI

Abstract
---
This case study argues that while AI offers unprecedented efficiency and innovation, it also presents significant risks to job sustainability, worker autonomy, and ethical labor practices unless properly regulated.

Introduction
---
With every invention that has had an impact on the daily lives of people, artificial intelligence (AI) is no exception. If anything, AI might become the invention that has one of the most salient impacts on human life. Many people believe that artificial intelligence is still in its early stages of life. As the development of artificial intelligence continues to accelerate and grow at immeasurable speeds, questions arise at the stability of the job market and the increasing concentration of technological power. This case study explores the central question: How will accelerating advances in AI reshape employment stability, and what ethical responsibilities do organizations and governments have in mitigating harm?

Background
---
While most people had not heard about artificial intelligence until 2020, AI has been around far longer than that. The earliest stages of AI are in what can be classified as the “Rule-Based” stage. The stage takes place from the years 1950-1970, some arguing the development commenced even earlier in the 40s. One of the highlights of the earliest models includes formal logic, which is an approach to represent concepts mathematically. These models lacked the ability to learn new information as the models relied solely on rules given when being programmed. 
### The effect on employment: 
Factories began incorporating machines that could follow fixed instructions, reducing the need for manual repetitive labor. Jobs in manufacturing, assembly lines, and logistics saw the first wave of displacement.

The second stage of artificial intelligence can be called the “Early Machine Learning” stage taking place from the year 1980-1990. The models being developed can now understand and ‘remember’ previous contexts to benefit the output of future responses. The second stage is where neural networks are introduced–inspired by the human brain and how it is structured. The machine learning aspect meant the models could improve their performance contingent on the amount and quality of data they were trained on. The stage where the early issues of the “black box” in AI emerge, where the models train and update themselves to the point where the developers are not particularly sure how the model works, but that it just does.
### The effect on employment: 
Data entry, simple accounting, and clerical work became partially automated through expert systems and early pattern-recognition tools. The workplace saw its first major divide between workers who could operate digital systems and those whose roles became redundant.

The third stage of AI models, taking place from 200-2010, can be thought of as the “No-Longer-Niche” stage. Models are being applied to more various domains. AI becomes more accessible to the typical person. This third stage is where people start seeing signs of artificial intelligence through things like Siri and voice recognition. 
### The effect on employment: 
Customer service chatbots and voice-recognition systems started handling basic inquiries. Retail, customer support, and call centers increasingly relied on automated systems to triage consumer requests.

The fourth stage is where, as of writing this in 2025, artificial intelligence is currently at. Starting from around 2010-2025/present, people start to see AI jump out of the shadows and start doing many things at unfathomable levels of uncanny. AI can now create music, write entire scripts for a musical, write code, and become one’s new best friend. The models are created with multi-dimensional neural networks called deep learning. The corpus, training data capacity, of the new language models are ginormous. “With 175 billion parameters, it represents one of the most sophisticated and largest language models to date.
### The effect on employment: 
Language models began writing, coding, translating, and analyzing information. Employers realized that knowledge work—journalism, law, finance, education—was no longer immune to automation. Creative tasks such as art, music, video editing, and even relationship-based roles became partially or fully automated. For the first time, knowledge and creative jobs face large-scale replacement.

History is showing that AI is evolving at an ever faster rate. "'[T]'here is little consensus on the nature and scale of generative AI’s potential impacts," meaning the majority of people don't even know how to properly respond and build up proper safety measures from avoiding harm  by artificial intelligence. 

Taken together, these four stages reveal a clear pattern. As AI evolves, the AI models move up the ladder of human skills--from physical labor to cognitive labor. Each leap expands the range of jobs that can be automated, bringing the issue of job sustainability into sharper focus.


Uncanny Interview
---
## "Despite high stakes for workers, we are not prepared for the potential risks and opportunities that generative AI is poised to bring. So far, the U.S. and other nations lack the urgency, mental models, worker power, policy solutions, and business practices needed for workers to benefit from AI and avoid its harms." - Kinder et al. 

In 2024, a part-time journalist, Mateusz Demski, was let go due to 'financial problems' from a morning show called Radio Kraków. The journalist has been working for the company for two year traveling to countries and interviewing a wide range of people and places--"from artists to activists." It was only a few months later when Radio Kraków started launching programs hosted by AI. 

Early on, the show screened a live interview with a guy by the name of Wisława Szymborska. Wisława had won the Nobel prize for her literature in 1996. There was just one peculiar thing about the interview. Wisława had died 12 years prior to the interview. The public "interview" of a dead person. The temerity of a company to ignore the ethical issues of such an interview. The story does not end here, for Radio Kraków. Read more about (Wisława's story)[https://www.theguardian.com/technology/2025/may/31/the-workers-who-lost-their-jobs-to-ai-chatgpt].

## "I couldn’t understand it: radio is created by people for other people. We cannot replace our experiences, emotions or voices with avatars." - Demski

People are losing their jobs left and right from artificial intelligence. "Wall Street expects to replace 200,000 roles with AI in the next 3 to 5 years" (Bloomberg). In fact, one of the things surveys are seeing is that the higher paying jobs are at more rist to being replaced by AI--earning on average $33.3/hour. Where the people least exposed to AI are earing on average $20/hour.

Jobs involving repetitive, data-driven, and knowledge-based tasks are most at risk of AI replacement. These roles often involve information processing, research, and writing, which generative AI excels at. 

Ethical Frameworks
---
## Utilitarian Perspective
What could be the benifits to replacing a journalist with AI? Ignoring the blatant moral issues to using AI to pixelate the deceased, what would be the harm in creating a "perfect" journalist to represent a company? A company would not have to pay for a journalist's expenses of time and travel. The company, such as the hiring department can save time, effort, and money. The society gains faster and cheaper content, making it more accessible to those on very low budgets. In the eyes of people who benefit from artificial intelligence, one might be quick to say an artificial journalist is ethical as it benefits the majority. One must ask themselves and think about who an artifical journalist really benefits. The "higher-ups" of the company. The workers of the company, like Mateusz working for Radio Kraków who recieve the concentrated harm, tend to lose their jobs, get paid less, are expected to get more done, or change the methods in which they do their jobs--often losing the fun in which why they applied there in the first place. 

The journalist losing his job is just one specific example. Numerous companies are replacing workers, many of whom who put their heart and soul into their work, with more 'efficient' AI tools. The utilitarian ethical framework says that something is ethical if it produces the greates good for the greatest number of people, focusing on consequences rather than intentions, aiming to maximize overall well-being and minimize suffering for everyone involved. However, the main people benefitting from the AI-journalist are the 'higher-up' people working for the company--not the workers who often have less financial independence and cannot afford to be replaced. Leaving the practice unethical as it aims for more revenue rather than the well-being of the overall people.

## Rights-Based 
Do workers have a right to meaningful empolyment? With workers who have spent their lives into a company only for them to be let go with no better reason than "you are no longer needed," the answer to the question is no. Mateusz was lucky in the fact that he was let go from his side job. Many people are let go from the main and only job. 

Is using an AI replica of a deceased person a violation of consent and dignity? The obvious answer is yes--absolutely. What happens when the people closest to the deceased journalist, who have mourned and suffered from her death, see them again on telivision? Nothing good. Not only is that so unithical of a company to do, but it is just plain disgusting. No consent, loss of dignity, and consumer harm, are just to name a few major issues with the act.

## Justice and Power
Similar to the rights-based ethical standpoint, job losses due to AI disproportionately affect creative an knowledge workers. Where the people making the decisions are not the people losing their jobs. Decision-making power lies with the firms, not the labor. So looking the ethics form a justice an power standpoint, it is very easily unethical. This imbalance in power means workers have little ability to influence decisions that directly impact their livelihoods. The benefits of AI adoption are concentrated among organizations and executives, while the risks and harms are largely absorbed by employees.


Solutions and Recommendations
---
While AI-driven automation cannot be fully reversed, the harms it causes to workers can be mitigated through deliberate and ethical decision-making by employers and governments. One possible solution is the implementation of human-in-the-loop policies, where AI systems assist rather than replace workers. In journalism, this could mean using AI for transcription, translation, or research support, while preserving human journalists as the primary creators and decision-makers. Not to temerariously revive a deceased person for television and revenue.

Another important solution is transparency in AI deployment. Companies should be required to clearly disclose when AI is being used in place of human labor, especially in creative or public-facing roles. In cases like Radio Kraków, transparency would allow audiences to understand whether content is produced by humans or AI, and would discourage deceptive or ethically questionable practices such as recreating deceased individuals without consent.

Governments also play a critical role in protecting workers affected by AI. Policy solutions could include stronger labor protections, mandatory notice periods before AI-related layoffs, and public investment in retraining and reskilling programs. These measures would help workers transition into new roles rather than being abruptly displaced by automation.

Finally, ethical guidelines and audits should be required for AI systems used in employment decisions. Independent oversight could help ensure that AI tools do not unfairly disadvantage workers, exploit creative labor, or concentrate benefits exclusively among executives. Without accountability, AI adoption risks deepening existing inequalities rather than promoting innovation that benefits society as a whole.

Conclusion
---
Artificial intelligence has the potential to transform industries, increase efficiency, and expand access to information, but its rapid adoption also raises serious ethical concerns about job sustainability and worker dignity. As this case study shows, AI does not impact all groups equally. Workers, particularly those in creative and knowledge-based roles, face concentrated harm while decision-making power remains largely in the hands of employers and technology developers.

Through the lens of utilitarian, rights-based, and justice-oriented ethical frameworks, it becomes clear that prioritizing efficiency and profit over human well-being leads to ethically questionable outcomes. Cases like the use of AI journalists at Radio Kraków highlight how automation can cross ethical boundaries when consent, transparency, and respect for labor are ignored.

The ethical challenge is not whether AI should exist, but how it should be used. Responsible AI adoption requires meaningful worker protections, transparency, and accountability from both organizations and governments. Without these measures, AI risks deepening inequality and undermining trust in institutions. With thoughtful regulation and ethical consideration, however, AI can be used to support human work rather than replace it.




[Go to activity page](activity/)

[Go to citations page](citations/)

[Go to stakeholder 1 (Workers)](stakeholder1/)

[Go to stakeholder 2 (Employers)](stakeholder2/)

[Go to stakeholder 3 (Government)](stakeholder3/)

