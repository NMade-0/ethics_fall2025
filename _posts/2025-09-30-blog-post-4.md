---
title: 'ALG Blog 2: How GenAI Works?!'
date: 2025-09-29
permalink: /posts/2025/09/blog-post-4/
tags:
  - case study
  - ethics
  - generative ai
---

**Words by an optimist – GenAI on my mind**

I recommend reading this case study first so you know what I’m reacting to:  
[How GenAI Works](https://mit-serc.pubpub.org/pub/f3o5mpn6/release/1?readingCollection=3a6c54f1)

Summary
---
This case study is about breaking down how generative AI actually works. It looks at four areas: how these models learn, the use of creative work for training, what "next-word prediction" really means, and the environmental costs that come with it.

## My Take – The Use of Creative Work for Training
So, here’s the deal: GenAI learns from huge piles of human-made content. That means art, music, blog posts, code, you name it. Once a model has all this data stored, it then learned off this data using really compliceated multi-dimensional neural-net sh*t. Then when a model is done learning--BAM!--new model.The upsides of models are AI can do very tedious tasks rather well, such as chaning the format of a cvs file to, perhaps, a JSON file. The downside, however, is lot of creators never agreed to have their work vacuumed up into a dataset. Artists get their works stolen. I think that’s shady, like pitch dark shady. If someone were to place a 4-mile thick, 2x2 mile wide block of conrete two millimeters from the ground at night in the equator, and you were to find the exact centor of the shadow it casts, it's that kinda shady we're talking. If someone put in the full-tilt back-breaking effort and painted a picture or wrote a story, they should at least have a say before it gets tossed into the training set for the models.

On the other hand: I’ve used and continue to use LLMs to help debug code or brainstorm creative stuff. That’s all possible because people’s work is in the model somewhere. So it’s tricky. I like the help, but I also think original creators should be credited or compensated in some way. Right now it feels like free labor that benefits tech companies way more than artists.

## My Question
If GenAI models had to start paying for training data, who gets the money and how would it be tracked? Would it be individual creators, or would it just go to publishers and companies who already own the rights?

I asked this because I want to know how "fair pay" for creative data could even work in practice, not just in theory. It’s easy to say "compensate artists," but the logistics sound like a nightmare.

## Reflection
I liked this case study because it peeled back the curtain on how these tools actually function. I use GenAI all the time, but I don’t always stop to think about the humans behind the training data. Reading this made me realize the stuff I generate with AI is kind of built on invisible foundations. My takeaway: if we’re gonna use GenAI, we need to keep talking about fairness, ownership, and who actually benefits from all this tech.

Final thought by the optimist: GenAI is cool, but it shouldn’t be powered by ghost labor.
