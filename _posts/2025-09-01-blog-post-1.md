---
title: 'First Blog?!'
date: 2025-09-16
permalink: /posts/2025/09/blog-post-1/
tags:
  - case study
  - first post
  - ethics
---

**Words by an optimist - AI as the Enemy**

I recommend reading this article first and coming up with your own perspectives and opions to AI, before reading my blog:
[AI—The good, the bad, and the scary](https://eng.vt.edu/magazine/stories/fall-2023/ai.html)

My Take
---
Reading an article on AI typically does a few things to my head—typically in the following order:

> 1: Damn, AI can do that!?
> 2: Well that's not good...
> 3: We're all dead

But, hey! After reading the article "AI—The good, the bad, and the scary," I had these thoughts run through my mind:

> 1: Damn, AI can do that!?
> 2: Well that's not good...
> 3: We're all dead

Okay I know, I know - call me an optimist - but I'm starting to think Stephen Hawking was onto something here when he said, "The developement of full artificial intelligence could spell the end of the human race." The quote sends shivers down my spine. I mean, Hawking was a smart guy, you can tell because he wore glasses.

Anyway, if you can forget the rough edges of AI - and if I can forget the jumping spider on the window next to me - I have answers my viewpoint to questions on AI and the article linked above;

## Why do I read these articles
Well, as a computer scientist, I like to know what is going on with artificial intelligence. It is important to me that I know the benefits and the risks with AI. I want to know what I am using when I ask and LLM for advice to solving an integral, or checking the syntax of a conditional in a coding language I haven't used in a while. If AI can solve my bug in my hundreds of lines of code and explain in detail what error I made, what and how much power does it really have? The article linked in this blog talked about these potentials and risks—interviewing people with different mediums of expertise.

## What are the real risks 
Well, I'm glad you asked! The biggest risks the article talked about are as followed in, what I believe, order from least risk to most risk:

- Stupdily good algorithms making the user stay on their phones, tvs, et cetera for longer and longer. I heard there is "$1 million prize to any team that could improve its recommendation algorithm, Cinematch, by at least 10%."

- We are relying more and more on AI. 
  I bet you the $1 million prize that I am planning on winning from Netflix, there are Gen Alphas who have never wrote their own essays without using and LLM to write the essay for them. As a result, our independent decision-making and thinking skills are at risk for deteriorating in future generations.

- Job security and sustainability is at an all-time risk with AI. As a computer scientist, I want to find a job where I won't get replaced in three years by a more-effecient AI tool. Nor do I want my data and info stolen through manipulative implementations of AI. With AI, scam callers, scam emails, scam anything can become more convicing through the use of AI.

- HUGE CARBON FOOTPRINT! Aren't we already in a exponential state of global warming? AI needs energy to compute at data centers. Those data centers need a lot of electricity "and also require a significant amount of water for cooling purposes." 

- Malicious intent is something the article didn't discuss a whole lot about, but it is the very thing I fear the most with AI. This ties to the previous one, but this goes further in the sense that AI can be, and has been, implemented into weapons. 

## Stakeholders
- The stakeholders of AI are pretty much everyone. Why would everyone be involved? Well, the consumers are affected by getting the short end of the stick in falling for the AI traps, such as deepfakes, biased job application scanning, addictive media etc. The people using AI are a stakeholder as they can rely on it's accuracy and efficiency. Teachers are stakeholder as their students probably use AI. I am a stakeholder, as I use it a lot to help me understand mathematical concepts that I fail to understand intuitive through just reading the book. Lot of people are using, relying, and burdened with AI.

## Ethical Issues
- The biggest issue with all the freedom and accessibility of AI, is we as a majority are seeing negative outcomes so far: job loss, deepfakes, homework-generated solutions in students of all ages, et cetera. This is unethical in the utilitarianism perspective as I fail to see how these outcomes are mostly good things to come out of the models. It feels like the exact opposite from when keep getting convincing videos on "world news" only to find out it was just a fake video generated through prompts. Another ethical framework that is broken is virtue, as with the power of AI brought in the salient greed of people in control. An example would be a social media company aking their websites as captivating and addicting as possible rather than thinking about the well being of the users spedning too much screen time on their website.

## So what can we do? 
- The best thing we can do is to put our brains back in our heads, and to set all greeds aside and write strong and growing laws about the uses of AI, create killswitches for new technologies,enforcing the laws of copyright infringement, introducing the founding of more people in charge with big and tipping decisions of future steps in AI, and creating better renewable practices of using and running AI to reduce the carbon footprint we have already created with it. That last sentence is definitely a run-on...

## Refelction
- AI is a very powerful tool. Not only is it super easy to access, but it is really easy to misuse. The misuse of AI can happen both intentionally and unintentionally. An example of each respectivly would be creating deepfakes or not learning how to properly write by just "chating" everything. We can use AI with the upmost caution and still unknowingly cause harm such as the amount of energy these models take to run. There are risks everywhere when using AI, we need to become aware of these risks, and weigh our options before entering a prompt.


## Final thought by the optimist

The second-worst thing that follows malicious use of AI, is the silence of those who know the very risks of it.