---
title: 'ALG Blog 2: How GenAI Works?!'
date: 2025-09-29
permalink: /posts/2025/09/blog-post-3/
tags:
  - case study
  - ethics
  - generative ai
---

**Words by an optimist – GenAI on my mind**

I recommend reading this case study first so you know what I’m reacting to:  
[How GenAI Works](https://mit-serc.pubpub.org/pub/f3o5mpn6/release/1?readingCollection=3a6c54f1)

Summary
---
This case study is about breaking down how generative AI actually works. It looks at four areas: how these models learn, the use of creative work for training, what "next-word prediction" really means, and the environmental costs that come with it.

## My Take – The Use of Creative Work for Training
So, here’s the deal: GenAI learns from huge piles of human-made content. That means art, music, blog posts, code, you name it. The upside is obvious, AI can create things that feel pretty close to what humans make. The downside? A lot of creators never agreed to have their work vacuumed up into a dataset. I think that’s shady. If someone painted a picture or wrote a story, they should at least have a say before it gets tossed into the training pot.

On the other hand: I’ve used and continue to use LLMs to help debug code or brainstorm creative stuff. That’s all possible because people’s work is in the model somewhere. So it’s tricky. I like the help, but I also think original creators should be credited or compensated in some way. Right now it feels like free labor that benefits tech companies way more than artists.

## My Question
If GenAI models had to start paying for training data, who gets the money and how would it be tracked? Would it be individual creators, or would it just go to publishers and companies who already own the rights?

I asked this because I want to know how "fair pay" for creative data could even work in practice, not just in theory. It’s easy to say "compensate artists," but the logistics sound like a nightmare.

## Reflection
I liked this case study because it peeled back the curtain on how these tools actually function. I use GenAI all the time, but I don’t always stop to think about the humans behind the training data. Reading this made me realize the stuff I generate with AI is kind of built on invisible foundations. My takeaway: if we’re gonna use GenAI, we need to keep talking about fairness, ownership, and who actually benefits from all this tech.

Final thought by the optimist: GenAI is cool, but it shouldn’t be powered by ghost labor.
