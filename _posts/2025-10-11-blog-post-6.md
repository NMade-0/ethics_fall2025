---
title: 'The Reality Of Us'
date: 2025-10-11
permalink: /posts/2025/11/blog-post-6/
tags:
  - case study
  - AI
  - companion
  - ethics
  - Addiction
---

Overview
---
This blog post is on the article ("Addictive Intelligence")[https://mit-serc.pubpub.org/pub/iopjyxcx/release/2?readingCollection=132bb7af] and my take on the five discussion questions posted at the end of the article. 

Summary
---
The article covers the rise of artificial intelligence, specifically focused on the rise of AI companions. Which, if you as the reader is unfamiliar, are large language models (think ChatGPT) that are trained and personified to provide real-time conversations on various subjects to the user. While the computational genius behind the models is remarkable and the fact that this was something of science fiction decade ago, the fact in the matter, is that these AI-companions are still just models. The personifictaion of these models leads to the ignorance, either blissed or from naivety, of their binary bits. The consequences from this misinterpetaion, and from the fact that no model is 100% hullucination-free, has led to fatal outcomes. Click on article title to check out the article or listen to the audio version provided.


Questions
---

#### 1. In the Sewell Setzer case, the AIâ€™s response to suicidal ideation shifted from concern to potentially encouraging harmful behavior. How can companies design AI companions to be emotionally engaging while preventing harmful psychological dependencies? Discuss both technical safeguards (e.g., algorithmic oversight, intervention protocols) and ethical guidelines (e.g., duty of care, transparency).

testing testing

2. How does addiction to AI companions compare with other forms of technology addiction, such as social media or gaming? What unique features make AI companions potentially more addictive? Support your analysis with examples from the case study and other relevant cases.

3. An elderly person finds genuine comfort in an AI companion, alleviating their loneliness, but their family worries this relationship is replacing real human connections. How should we evaluate the benefits versus risks in such cases? What ethical guidelines or intervention strategies might help determine when AI companionship crosses from beneficial to harmful?

4. Current business models incentivize AI companies to maximize user engagement. What alternative economic models could promote healthier AI interactions while maintaining commercial viability? Consider both market-driven solutions (e.g., subscription-based models, ethical AI certifications) and regulatory approaches (e.g., user well-being metrics, engagement caps).

5. If you were developing regulations for AI companions, how would you address age restrictions, usage limits, and safety monitoring while respecting user privacy and autonomy? Provide specific examples of how your proposed regulations could have helped prevent incidents like the Sewell Setzer case.